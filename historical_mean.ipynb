{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from utils import create_wfv_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buurtcode</th>\n",
       "      <th>a00a</th>\n",
       "      <th>a00b</th>\n",
       "      <th>a00c</th>\n",
       "      <th>a00d</th>\n",
       "      <th>a00e</th>\n",
       "      <th>a01a</th>\n",
       "      <th>a01b</th>\n",
       "      <th>a01c</th>\n",
       "      <th>a01d</th>\n",
       "      <th>a01e</th>\n",
       "      <th>...</th>\n",
       "      <th>t96d</th>\n",
       "      <th>t96e</th>\n",
       "      <th>t96f</th>\n",
       "      <th>t96g</th>\n",
       "      <th>t97a</th>\n",
       "      <th>t97b</th>\n",
       "      <th>t97c</th>\n",
       "      <th>t97d</th>\n",
       "      <th>t98a</th>\n",
       "      <th>t98b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scnMoment</th>\n",
       "      <th>scnMoment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6</th>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.690501</td>\n",
       "      <td>0.508266</td>\n",
       "      <td>0.771743</td>\n",
       "      <td>0.894849</td>\n",
       "      <td>0.830548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.761412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.736965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.662869</td>\n",
       "      <td>0.461740</td>\n",
       "      <td>0.850733</td>\n",
       "      <td>0.895590</td>\n",
       "      <td>0.861088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.764746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.780746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.689147</td>\n",
       "      <td>0.498138</td>\n",
       "      <td>0.846392</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.839159</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.780930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.801797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.662592</td>\n",
       "      <td>0.451184</td>\n",
       "      <td>0.823421</td>\n",
       "      <td>0.859089</td>\n",
       "      <td>0.838432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.778740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.743035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>13</th>\n",
       "      <td>0.703500</td>\n",
       "      <td>0.582238</td>\n",
       "      <td>0.844373</td>\n",
       "      <td>0.890888</td>\n",
       "      <td>0.876578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.813641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.692278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830617</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.883879</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.801547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.764710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.655532</td>\n",
       "      <td>0.534554</td>\n",
       "      <td>0.812028</td>\n",
       "      <td>0.812762</td>\n",
       "      <td>0.817295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.728225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701877</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.511715</td>\n",
       "      <td>0.573389</td>\n",
       "      <td>0.775057</td>\n",
       "      <td>0.787677</td>\n",
       "      <td>0.810272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.433136</td>\n",
       "      <td>0.440723</td>\n",
       "      <td>0.784500</td>\n",
       "      <td>0.774781</td>\n",
       "      <td>0.776619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.689767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12955 rows Ã— 481 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "buurtcode                a00a      a00b      a00c      a00d      a00e  \\\n",
       "scnMoment scnMoment                                                     \n",
       "6         9               NaN       NaN       NaN       NaN       NaN   \n",
       "          12         0.690501  0.508266  0.771743  0.894849  0.830548   \n",
       "          13         0.662869  0.461740  0.850733  0.895590  0.861088   \n",
       "          14         0.689147  0.498138  0.846392  0.652174  0.839159   \n",
       "          15         0.662592  0.451184  0.823421  0.859089  0.838432   \n",
       "...                       ...       ...       ...       ...       ...   \n",
       "0         13         0.703500  0.582238  0.844373  0.890888  0.876578   \n",
       "          14         0.692278       NaN  0.830617  0.608696  0.883879   \n",
       "          15         0.655532  0.534554  0.812028  0.812762  0.817295   \n",
       "          16         0.511715  0.573389  0.775057  0.787677  0.810272   \n",
       "          17         0.433136  0.440723  0.784500  0.774781  0.776619   \n",
       "\n",
       "buurtcode                a01a      a01b  a01c      a01d  a01e  ...  t96d  \\\n",
       "scnMoment scnMoment                                            ...         \n",
       "6         9               NaN       NaN   NaN       NaN   NaN  ...   NaN   \n",
       "          12              NaN  0.761412   NaN  0.736965   NaN  ...   NaN   \n",
       "          13              NaN  0.764746   NaN  0.780746   NaN  ...   NaN   \n",
       "          14         0.058824  0.780930   NaN  0.801797   NaN  ...   NaN   \n",
       "          15              NaN  0.778740   NaN  0.743035   NaN  ...   NaN   \n",
       "...                       ...       ...   ...       ...   ...  ...   ...   \n",
       "0         13              NaN  0.775580   NaN  0.813641   NaN  ...   NaN   \n",
       "          14              NaN  0.801547   NaN  0.764710   NaN  ...   NaN   \n",
       "          15              NaN  0.728225   NaN  0.701877   NaN  ...   NaN   \n",
       "          16              NaN  0.755318   NaN  0.717493   NaN  ...   NaN   \n",
       "          17              NaN  0.718340   NaN  0.689767   NaN  ...   NaN   \n",
       "\n",
       "buurtcode            t96e  t96f  t96g  t97a  t97b  t97c  t97d  t98a  t98b  \n",
       "scnMoment scnMoment                                                        \n",
       "6         9           NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "          12          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "          13          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "          14          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "          15          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...                   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "0         13          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "          14          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "          15          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "          16          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "          17          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[12955 rows x 481 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = True\n",
    "testing = True\n",
    "n_splits = 3\n",
    "test_idx = 2\n",
    "mean_types = [\"global\", \"hour\", \"day\", \"buurt\", \"buurt_hour\", \"buurt_dayhour\"]\n",
    "\n",
    "target_df = pd.read_pickle(\"data/PARKING/raw/target_df_aantal_cleaned_new.pkl\").dropna(how=\"all\")\n",
    "wfv_splits, train_size, test_size = create_wfv_splits(target_df, n_splits)\n",
    "target_df.index = [target_df.index.dayofweek, target_df.index.hour]\n",
    "\n",
    "mean_df = target_df\n",
    "mean_df = mean_df.groupby(mean_df.index).mean()\n",
    "mean_df = mean_df.reindex(target_df.index)\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[range(0, 9751), range(9751, 10696)],\n",
       "       [range(0, 10696), range(10696, 11824)],\n",
       "       [range(0, 11824), range(11824, 12955)]], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfv_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   train      val\n",
      "global         | 0.188593   | 0.191064   |\n",
      "hour           | 0.180692   | 0.183898   |\n",
      "day            | 0.188357   | 0.191050   |\n",
      "buurt          | 0.110265   | 0.118706   |\n",
      "buurt_hour     | 0.091821   | 0.105004   |\n",
      "buurt_dayhour  | 0.083832   | 0.105532   |\n",
      "\n",
      "                    train      test\n",
      "global         | 0.188973   | 0.198726   |\n",
      "hour           | 0.181165   | 0.194667   |\n",
      "day            | 0.188756   | 0.198265   |\n",
      "buurt          | 0.110666   | 0.115227   |\n",
      "buurt_hour     | 0.092923   | 0.105011   |\n",
      "buurt_dayhour  | 0.085343   | 0.103991   |\n"
     ]
    }
   ],
   "source": [
    "train_losses_df = pd.DataFrame(index=range(len(wfv_splits)), columns=mean_types, dtype = np.float64)\n",
    "val_losses_df = pd.DataFrame(index=range(len(wfv_splits)), columns=mean_types, dtype = np.float64)\n",
    "\n",
    "for mean_num, mean_type in enumerate(mean_types):\n",
    "    target_df = pd.read_pickle(\"data/PARKING/raw/target_df_aantal_cleaned_new.pkl\").dropna(how=\"all\")\n",
    "    \n",
    "    if mean_type == \"hour\" or mean_type == \"buurt_hour\":\n",
    "        target_df.index = target_df.index.hour\n",
    "    elif mean_type == \"day\":\n",
    "        target_df.index = target_df.index.dayofweek\n",
    "    elif mean_type == \"buurt_dayhour\":\n",
    "        target_df.index = [target_df.index.dayofweek, target_df.index.hour]\n",
    "    results = []\n",
    "\n",
    "    for split_idx, (train_index, val_index) in enumerate(wfv_splits):\n",
    "        if (not training and split_idx < test_idx) or (not testing and split_idx >= test_idx): continue\n",
    "            \n",
    "        X_train = target_df.iloc[train_index]\n",
    "        X_val = target_df.iloc[val_index]\n",
    "\n",
    "        if mean_type == \"buurt_hour\" or mean_type == \"buurt_dayhour\":\n",
    "            mean_df = X_train.groupby(X_train.index).mean()\n",
    "            mean_df = mean_df.fillna(mean_df.mean())\n",
    "            train_err_df = X_train - mean_df.reindex(X_train.index)\n",
    "            val_err_df = X_val - mean_df.reindex(X_val.index)\n",
    "        else:\n",
    "            if mean_type == \"hour\" or mean_type == \"day\":\n",
    "                idx, values = zip(*[(x, np.nanmean(y)) for x, y in X_train.groupby(X_train.index)])\n",
    "                train_err_df = X_train.sub(pd.Series(values, idx).reindex(X_train.index), axis=\"index\")\n",
    "                val_err_df = X_val.sub(pd.Series(values, idx).reindex(X_val.index), axis=\"index\")\n",
    "            else:\n",
    "                if mean_type == \"global\":\n",
    "                    mean_df = np.nanmean(X_train)\n",
    "                    val_err_df = X_val - mean_df\n",
    "                elif mean_type == \"buurt\":\n",
    "                    mean_df = X_train.mean()\n",
    "                    val_err_df = X_val - mean_df.fillna(mean_df.mean())\n",
    "                train_err_df = X_train - mean_df\n",
    "                \n",
    "\n",
    "        train_losses_df.iloc[split_idx, mean_num] = (np.nanmean(train_err_df ** 2)) ** 0.5\n",
    "        val_losses_df.iloc[split_idx, mean_num] = (np.nanmean(val_err_df ** 2)) ** 0.5\n",
    "\n",
    "if training:\n",
    "    print(\" \"*18, 'train', \" \"*4, 'val')\n",
    "    for mean_num, mean_type in enumerate(mean_types):\n",
    "        print('{:<14s} | {:<10f} | {:<10f} |'.format(mean_type, np.average(train_losses_df.iloc[:test_idx, mean_num], weights = train_size[:test_idx]), \n",
    "                                                                np.average(val_losses_df.iloc[:test_idx, mean_num], weights = test_size[:test_idx])))\n",
    "\n",
    "if testing:\n",
    "    print(\"\\n\", \" \"*18, 'train', \" \"*4, 'test')\n",
    "    for mean_num, mean_type in enumerate(mean_types):\n",
    "        print('{:<14s} | {:<10f} | {:<10f} |'.format(mean_type, np.average(train_losses_df.iloc[test_idx:, mean_num], weights = train_size[test_idx:]), \n",
    "                                                                np.average(val_losses_df.iloc[test_idx:, mean_num], weights = test_size[test_idx:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>buurt</th>\n",
       "      <th>buurt_hour</th>\n",
       "      <th>buurt_dayhour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.188587</td>\n",
       "      <td>0.180663</td>\n",
       "      <td>0.188332</td>\n",
       "      <td>0.109780</td>\n",
       "      <td>0.090949</td>\n",
       "      <td>0.082780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.188599</td>\n",
       "      <td>0.180718</td>\n",
       "      <td>0.188380</td>\n",
       "      <td>0.110705</td>\n",
       "      <td>0.092612</td>\n",
       "      <td>0.084786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.188973</td>\n",
       "      <td>0.181165</td>\n",
       "      <td>0.188756</td>\n",
       "      <td>0.110666</td>\n",
       "      <td>0.092923</td>\n",
       "      <td>0.085343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     global      hour       day     buurt  buurt_hour  buurt_dayhour\n",
       "0  0.188587  0.180663  0.188332  0.109780    0.090949       0.082780\n",
       "1  0.188599  0.180718  0.188380  0.110705    0.092612       0.084786\n",
       "2  0.188973  0.181165  0.188756  0.110666    0.092923       0.085343"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>buurt</th>\n",
       "      <th>buurt_hour</th>\n",
       "      <th>buurt_dayhour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.189302</td>\n",
       "      <td>0.181830</td>\n",
       "      <td>0.189478</td>\n",
       "      <td>0.126628</td>\n",
       "      <td>0.112171</td>\n",
       "      <td>0.113676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.192696</td>\n",
       "      <td>0.185815</td>\n",
       "      <td>0.192507</td>\n",
       "      <td>0.111362</td>\n",
       "      <td>0.098360</td>\n",
       "      <td>0.097983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.198726</td>\n",
       "      <td>0.194667</td>\n",
       "      <td>0.198265</td>\n",
       "      <td>0.115227</td>\n",
       "      <td>0.105011</td>\n",
       "      <td>0.103991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     global      hour       day     buurt  buurt_hour  buurt_dayhour\n",
       "0  0.189302  0.181830  0.189478  0.126628    0.112171       0.113676\n",
       "1  0.192696  0.185815  0.192507  0.111362    0.098360       0.097983\n",
       "2  0.198726  0.194667  0.198265  0.115227    0.105011       0.103991"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_losses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.085343\n",
       "Name: buurt_dayhour, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses_df.iloc[test_idx:, mean_num]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08383226960649302"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(train_losses_df.iloc[:test_idx, mean_num], weights = train_size[:test_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buurtcode</th>\n",
       "      <th>polygon</th>\n",
       "      <th>centroid</th>\n",
       "      <th>norm_centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>a00a</td>\n",
       "      <td>POLYGON ((122045.505 487745.336, 122026.815 48...</td>\n",
       "      <td>POINT (121841.64116914148 487673.3461266836)</td>\n",
       "      <td>POINT (0.027989097150902 0.1717701745775366)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>a00b</td>\n",
       "      <td>POLYGON ((121782.088 487542.257, 121770.331 48...</td>\n",
       "      <td>POINT (121559.47899824797 487437.3476033915)</td>\n",
       "      <td>POINT (0.0004469220902971 0.1444060134852146)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>a00c</td>\n",
       "      <td>POLYGON ((121885.329 487401.961, 121908.361 48...</td>\n",
       "      <td>POINT (121735.38780294551 487327.7959828982)</td>\n",
       "      <td>POINT (0.0176175834810113 0.1317034416670286)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>a00d</td>\n",
       "      <td>POLYGON ((121539.554 487222.451, 121467.922 48...</td>\n",
       "      <td>POINT (121391.6158944025 487112.2825822399)</td>\n",
       "      <td>POINT (-0.0159383891570899 0.106714542029424)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>a00e</td>\n",
       "      <td>POLYGON ((121734.944 487124.933, 121620.093 48...</td>\n",
       "      <td>POINT (121517.8818392263 486964.5833259047)</td>\n",
       "      <td>POINT (-0.0036134245967536 0.0895887304472436)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    buurtcode                                            polygon  \\\n",
       "221      a00a  POLYGON ((122045.505 487745.336, 122026.815 48...   \n",
       "318      a00b  POLYGON ((121782.088 487542.257, 121770.331 48...   \n",
       "76       a00c  POLYGON ((121885.329 487401.961, 121908.361 48...   \n",
       "275      a00d  POLYGON ((121539.554 487222.451, 121467.922 48...   \n",
       "23       a00e  POLYGON ((121734.944 487124.933, 121620.093 48...   \n",
       "\n",
       "                                         centroid  \\\n",
       "221  POINT (121841.64116914148 487673.3461266836)   \n",
       "318  POINT (121559.47899824797 487437.3476033915)   \n",
       "76   POINT (121735.38780294551 487327.7959828982)   \n",
       "275   POINT (121391.6158944025 487112.2825822399)   \n",
       "23    POINT (121517.8818392263 486964.5833259047)   \n",
       "\n",
       "                                      norm_centroid  \n",
       "221    POINT (0.027989097150902 0.1717701745775366)  \n",
       "318   POINT (0.0004469220902971 0.1444060134852146)  \n",
       "76    POINT (0.0176175834810113 0.1317034416670286)  \n",
       "275   POINT (-0.0159383891570899 0.106714542029424)  \n",
       "23   POINT (-0.0036134245967536 0.0895887304472436)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buurt_df = pd.read_pickle(\"data/PARKING/raw/buurt_polygons.pkl\")\n",
    "buurt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import repeat\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# buurt_df = buurt_df.set_index('buurtcode')\n",
    "idx_map = {j: i for i, j in enumerate(buurt_df.index)}\n",
    "buurt_gdf = gpd.GeoDataFrame(geometry=buurt_df.polygon)\n",
    "\n",
    "edges_unordered = np.concatenate([list(zip(buurt_gdf.index[buurt_gdf.touches(row.geometry)], repeat(code))) \n",
    "                            for code, row in buurt_gdf.iterrows()])\n",
    "edges = np.array(list(map(idx_map.get, edges_unordered.flatten()))).reshape(edges_unordered.shape)\n",
    "\n",
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                    shape=(len(buurt_gdf), len(buurt_gdf)))\n",
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "adj = normalize(adj + sp.eye(adj.shape[0]))\n",
    "adj = sparse_mx_to_torch_sparse_tensor(adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'\n",
    "    \n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nout, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, nout)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/processed_targets/target_df_aantal_cleaned_new.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m hidden_num \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[1;32m      6\u001b[0m output_dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m----> 7\u001b[0m target_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_pickle(\u001b[39m\"\u001b[39;49m\u001b[39m../../data/processed_targets/target_df_aantal_cleaned_new.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mdropna(how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m input_list \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mcyclical_hour\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcyclical_day\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcentroid\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbbga\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnpr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhistorical\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m all_combinations \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/pickle.py:196\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39m>>> os.remove(\"./dummy.pkl\")\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    195\u001b[0m excs_to_catch \u001b[39m=\u001b[39m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m)\n\u001b[0;32m--> 196\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    197\u001b[0m     filepath_or_buffer,\n\u001b[1;32m    198\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    199\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    200\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    201\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    202\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    203\u001b[0m \n\u001b[1;32m    204\u001b[0m     \u001b[39m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[39m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[39m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m         \u001b[39m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    210\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/common.py:711\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    702\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    703\u001b[0m             handle,\n\u001b[1;32m    704\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    707\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    708\u001b[0m         )\n\u001b[1;32m    709\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    710\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 711\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    712\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    714\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/processed_targets/target_df_aantal_cleaned_new.pkl'"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "adj = adj.to(device)\n",
    "max_epochs = 50\n",
    "max_folds = 3\n",
    "hidden_num = 50\n",
    "output_dim = 1\n",
    "target_df = pd.read_pickle(\"../../data/processed_targets/target_df_aantal_cleaned_new.pkl\").dropna(how=\"all\")\n",
    "\n",
    "input_list = [\"cyclical_hour\", \"cyclical_day\", \"centroid\", \"bbga\", \"npr\", \"historical\"]\n",
    "all_combinations = []\n",
    "for r in range(1, len(input_list) + 1):\n",
    "    all_combinations += list(itertools.combinations(input_list, r))\n",
    "    \n",
    "for input_types in [[\"cyclical_hour\", \"cyclical_day\", \"centroid\", \"bbga\", \"npr\", \"historical\"]]:\n",
    "    \n",
    "    train_losses_df = pd.DataFrame(index=range(max_epochs), columns=range(max_folds))\n",
    "    test_losses_df = pd.DataFrame(index=range(max_epochs), columns=range(max_folds))\n",
    "    \n",
    "    train_index = int(len(target_df)*0.70)\n",
    "    val_index = int(len(target_df)*0.80)\n",
    "    training_set = Dataset(input_types, target_df.iloc[:train_index])\n",
    "    val_set = Dataset(input_types, target_df.iloc[train_index:val_index])\n",
    "    \n",
    "#     tscv = TimeSeriesSplit(n_splits=max_folds)\n",
    "#     for nfold, (train_index, test_index) in enumerate(tscv.split(target_df)):\n",
    "\n",
    "    for nfold in range(max_folds):\n",
    "        if nfold == 0: print(input_types, \":\", training_set[0][0].shape)\n",
    "    \n",
    "        model = GCN(nfeat=training_set[0][0].shape[-1], nhid=hidden_num, nout=output_dim, dropout=0.2).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay = 1e-4)\n",
    "\n",
    "        for epoch in range(max_epochs):\n",
    "            train_losses, test_losses = [], []\n",
    "\n",
    "            training_generator = torch.utils.data.DataLoader(training_set)\n",
    "            test_generator = torch.utils.data.DataLoader(val_set)\n",
    "\n",
    "            model.train()\n",
    "            for x, y in training_generator:\n",
    "                mask = ~torch.isnan(y[0])\n",
    "                x, y, mask = x[0].to(device), y[0].to(device), mask.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x, adj).flatten()\n",
    "                loss = loss_fn(outputs[mask], y[mask])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_losses.append(loss.detach().cpu().item())\n",
    "            train_losses_df.iloc[epoch, nfold] = np.mean(train_losses)\n",
    "\n",
    "            model.eval()\n",
    "            for x, y in test_generator:\n",
    "                mask = ~torch.isnan(y[0])\n",
    "                x, y, mask = x[0].to(device), y[0].to(device), mask.to(device)\n",
    "                outputs = model(x, adj).flatten()\n",
    "                loss = loss_fn(outputs[mask], y[mask])\n",
    "                test_losses.append(loss.detach().cpu().item())\n",
    "            test_losses_df.iloc[epoch, nfold] = np.mean(test_losses)\n",
    "            print(\"epoch:\", epoch)\n",
    "            print(\"training loss:\", train_losses_df.iloc[epoch, nfold])\n",
    "            print(\"test loss:\", test_losses_df.iloc[epoch, nfold])\n",
    "        print(\"nfold:\", nfold)\n",
    "        print(\"training loss:\", train_losses_df.iloc[epoch, nfold])\n",
    "        print(\"test loss:\", test_losses_df.iloc[epoch, nfold])\n",
    "    print(\"mean training loss:\", train_losses_df.iloc[-1,:].mean())\n",
    "    print(\"mean testing loss:\", test_losses_df.iloc[-1,:].mean())\n",
    "\n",
    "    train_losses_df.plot()\n",
    "    test_losses_df.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, input_types, target_df):\n",
    "        'Initialization'\n",
    "        bbga_df = pd.read_pickle(\"../../data/processed_inputs/bbga_pca.pkl\")\n",
    "        spatial_polygons = pd.read_pickle(\"../../data/processed_inputs/buurt_polygons.pkl\")\n",
    "        \n",
    "        self.input_types = input_types\n",
    "        self.batch_size = target_df.shape[-1]\n",
    "        self.time_idx = target_df.index\n",
    "        self.time_range = pd.date_range(start=self.time_idx[0], end=self.time_idx[-1], freq='H')\n",
    "        self.hour_one_hot = torch.nn.functional.one_hot(torch.LongTensor(target_df.index.hour)).float()\n",
    "        self.day_one_hot = torch.nn.functional.one_hot(torch.LongTensor(target_df.index.dayofweek)).float()\n",
    "        self.spatial_one_hot = torch.eye(self.batch_size)\n",
    "        self.spatial_centroid = torch.Tensor(np.vstack([[p.x, p.y] for p in spatial_polygons['norm_centroid']]))\n",
    "        self.bbga_data = torch.Tensor(bbga_df.loc[2018].T.values)\n",
    "        self.cyclical_hour = torch.Tensor([np.sin(2*np.pi*target_df.index.hour/24), np.cos(2*np.pi*target_df.index.hour/24)]).T\n",
    "        self.cyclical_day = torch.Tensor([np.sin(2*np.pi*target_df.index.dayofweek/24), np.cos(2*np.pi*target_df.index.dayofweek/24)]).T\n",
    "\n",
    "        self.historical_values = target_df.reindex(self.time_range).shift()\n",
    "        \n",
    "        if \"npr\" in input_types:\n",
    "            self.npr_occ = pd.read_csv(\"../../data/raw_buurt_info/NPR_PRC_Stacked_Occupation.csv\", sep = ';')\n",
    "            self.npr_occ[\"buurtcode\"] = self.npr_occ[\"buurtcode\"].str.lower()\n",
    "            self.npr_occ = pd.melt(self.npr_occ, id_vars=['buurtcode', 'B_TYD_V_RECHT'], value_vars=self.npr_occ.columns[3:], value_name='count')\n",
    "            self.npr_occ['interval_start'] = pd.to_datetime(self.npr_occ['B_TYD_V_RECHT'] + '-' + self.npr_occ['variable'].str[5:], format='%Y-%m-%d-%H')\n",
    "            self.npr_occ = self.npr_occ.groupby(['buurtcode', 'interval_start']).sum().unstack(level=0)\n",
    "            self.npr_occ = self.npr_occ.droplevel(level=0, axis=1)\n",
    "            self.npr_occ = self.npr_occ.shift().reindex(self.time_range, columns=target_df.columns)\n",
    "        \n",
    "        self.y = torch.Tensor(target_df.values)\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        time_idx = self.time_idx[index]\n",
    "        feature_list = []\n",
    "        for input_type in self.input_types:\n",
    "            if input_type == \"global\":\n",
    "                feature_list.append(torch.ones(self.batch_size, 1))\n",
    "            if input_type == \"hour\":\n",
    "                feature_list.append(self.hour_one_hot[index].expand(self.batch_size, -1))\n",
    "            if input_type == \"day\":\n",
    "                feature_list.append(self.day_one_hot[index].expand(self.batch_size, -1))\n",
    "            if input_type == \"cyclical_hour\":\n",
    "                feature_list.append(self.cyclical_hour[index].expand(self.batch_size, -1))\n",
    "            if input_type == \"cyclical_day\":\n",
    "                feature_list.append(self.cyclical_day[index].expand(self.batch_size, -1))\n",
    "            if input_type == \"neighbourhood\":\n",
    "                feature_list.append(self.spatial_one_hot)\n",
    "            if input_type == \"centroid\":\n",
    "                feature_list.append(self.spatial_centroid)\n",
    "            if input_type == \"bbga\":\n",
    "                feature_list.append(self.bbga_data)\n",
    "            if input_type == \"historical\":\n",
    "                feature_list.append(torch.Tensor(np.stack((self.historical_values.loc[time_idx].fillna(0), self.historical_values.loc[time_idx].notnull()), axis=1)))\n",
    "            if input_type == \"npr\":\n",
    "                feature_list.append(torch.Tensor(np.stack((self.npr_occ.loc[time_idx].fillna(0), self.npr_occ.loc[time_idx].notnull()), axis=1)))\n",
    "        x = torch.cat((feature_list), -1)\n",
    "        y = self.y[index]\n",
    "        mask = ~torch.isnan(y)\n",
    "        return x[mask], y[mask]\n",
    "    \n",
    "target_df = pd.read_pickle(\"../../data/processed_targets/target_df_aantal_cleaned_new.pkl\").dropna(how=\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
