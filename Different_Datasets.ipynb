{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2bdfb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renzo/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[7489, 3], edge_index=[2, 59912], edge_attr=[59912], y=[64], pos=[7489, 2], batch=[7489], ptr=[65])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch_geometric.datasets import GNNBenchmarkDataset, TUDataset\n",
    "from torch_geometric.transforms.add_positional_encoding import AddLaplacianEigenvectorPE\n",
    "from torch_geometric.loader import DataLoader\n",
    "from IST_models import RMGN\n",
    "from utils import merge_model_parameters, hierarchical_graphs, build_network_params, count_parameters\n",
    "\n",
    "data_name = \"CIFAR10\"\n",
    "model_root = 'data/MODELS/'\n",
    "\n",
    "dataset_train = GNNBenchmarkDataset(root = \"data/\" + data_name, name = data_name, split=\"train\")\n",
    "dataset_val = GNNBenchmarkDataset(root = \"data/\" + data_name, name = data_name, split=\"val\")\n",
    "dataset_test = GNNBenchmarkDataset(root = \"data/\" + data_name, name = data_name, split=\"test\")\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(dataset_val, batch_size=64)\n",
    "test_loader = DataLoader(dataset_test, batch_size=64)\n",
    "\n",
    "# from torch_loader import GraphClassificationBench\n",
    "\n",
    "# # Load \"hard\"\n",
    "# dataset_train = GraphClassificationBench(\"data/\", split='train', easy=False, small=False)\n",
    "# dataset_val = GraphClassificationBench(\"data/\", split='val', easy=False, small=False)\n",
    "# dataset_test = GraphClassificationBench(\"data/\", split='test', easy=False, small=False)\n",
    "\n",
    "# train_loader = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "# valid_loader = DataLoader(dataset_val, batch_size=32)\n",
    "# test_loader = DataLoader(dataset_test, batch_size=32)\n",
    "\n",
    "emb_bias = True\n",
    "if data_name == \"CIFAR10\":\n",
    "    return_level = \"graph_level\"\n",
    "    from utils import accuracy_MNIST_CIFAR as accuracy\n",
    "    from utils import loss_MNIST_CIFAR as loss_funtion\n",
    "    num_features = 5\n",
    "    emb_bias = True\n",
    "elif data_name == \"PATTERN\":\n",
    "    return_level = \"node_level\"\n",
    "    from utils import accuracy_SBM as accuracy\n",
    "    from utils import loss_SBM as loss_funtion\n",
    "    emb_bias = False\n",
    "    num_features = 3\n",
    "elif data_name == \"CLUSTER\":\n",
    "    return_level = \"node_level\"\n",
    "    from utils import accuracy_SBM as accuracy\n",
    "    from utils import loss_SBM as loss_funtion\n",
    "    emb_bias = False\n",
    "    num_features = 7\n",
    "elif data_name == \"MNIST\":\n",
    "    return_level = \"node_level\"\n",
    "    from utils import accuracy_MNIST_CIFAR as accuracy\n",
    "    from utils import loss_MNIST_CIFAR as loss_funtion\n",
    "    emb_bias = True\n",
    "    num_features = 3\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26e7b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_encoder.0.weight :  torch.Size([100, 5])\n",
      "S_encoder.0.bias :  torch.Size([100])\n",
      "S_processor.0.0.model.1.node_project_fn.weight :  torch.Size([100, 200])\n",
      "S_processor.0.0.model.1.node_project_fn.bias :  torch.Size([100])\n",
      "S_processor.0.0.model.1.normalize_fn.weight :  torch.Size([100])\n",
      "S_processor.0.0.model.1.normalize_fn.bias :  torch.Size([100])\n",
      "S_processor.1.0.model.1.node_project_fn.weight :  torch.Size([100, 200])\n",
      "S_processor.1.0.model.1.node_project_fn.bias :  torch.Size([100])\n",
      "S_processor.1.0.model.1.normalize_fn.weight :  torch.Size([100])\n",
      "S_processor.1.0.model.1.normalize_fn.bias :  torch.Size([100])\n",
      "S_processor.2.0.model.1.node_project_fn.weight :  torch.Size([100, 200])\n",
      "S_processor.2.0.model.1.node_project_fn.bias :  torch.Size([100])\n",
      "S_processor.2.0.model.1.normalize_fn.weight :  torch.Size([100])\n",
      "S_processor.2.0.model.1.normalize_fn.bias :  torch.Size([100])\n",
      "S_processor.3.0.model.1.node_project_fn.weight :  torch.Size([100, 200])\n",
      "S_processor.3.0.model.1.node_project_fn.bias :  torch.Size([100])\n",
      "S_processor.3.0.model.1.normalize_fn.weight :  torch.Size([100])\n",
      "S_processor.3.0.model.1.normalize_fn.bias :  torch.Size([100])\n",
      "after_model.0.weight :  torch.Size([50, 100])\n",
      "after_model.0.bias :  torch.Size([50])\n",
      "after_model.2.weight :  torch.Size([25, 50])\n",
      "after_model.2.bias :  torch.Size([25])\n",
      "after_model.4.weight :  torch.Size([10, 25])\n",
      "after_model.4.bias :  torch.Size([10])\n",
      "\n",
      " Total number of Parameters  Graph_Sage_mean :  88385\n"
     ]
    }
   ],
   "source": [
    "model_dict = {\n",
    "    \"Graph_Sage_pool\": {\n",
    "        \"edge_params\": {\n",
    "            \"project\": True,\n",
    "            \"activation\": \"relu\",\n",
    "            \"initial_loops\": False,\n",
    "            \"with_nodes_own\": True,\n",
    "        },\n",
    "        \"node_params\": {\n",
    "            \"edge_to_node_aggr\": \"max\",\n",
    "            \"project\": True,\n",
    "            \"activation\": \"relu\",\n",
    "            \"with_nodes_own\": True,\n",
    "        },\n",
    "        \"selection_params\": {\n",
    "            \"remove_self_loops\": True\n",
    "        }\n",
    "    },\n",
    "    \"Graph_Sage_mean\": {\n",
    "        \"edge_params\": {\n",
    "            \"edge_att_norm\": \"mean\",\n",
    "            \"project\": False,\n",
    "            \"initial_loops\": False,\n",
    "            \"with_nodes_own\": True\n",
    "        },\n",
    "        \"node_params\": {\n",
    "            \"edge_to_node_aggr\": \"sum\",\n",
    "            \"project\": True,\n",
    "            \"activation\": \"relu\",\n",
    "            \"with_nodes_own\": True,\n",
    "        },\n",
    "        \"selection_params\": {\n",
    "            \"remove_self_loops\": True\n",
    "        }\n",
    "    },\n",
    "    \"Graph_Sage_vanilla\": {\n",
    "        \"edge_params\": {\n",
    "            \"edge_att_norm\": \"mean\",\n",
    "            \"project\": False,\n",
    "            \"initial_loops\": True,\n",
    "            \"with_nodes_own\": True,\n",
    "        },\n",
    "        \"node_params\": {\n",
    "            \"edge_to_node_aggr\": \"sum\",\n",
    "            \"project\": True,\n",
    "            \"activation\": \"relu\",\n",
    "        },\n",
    "        \"selection_params\": {\n",
    "        }\n",
    "    },\n",
    "    \"Graph_Sage_GCN\": {\n",
    "        \"edge_params\": {\n",
    "            \"edge_att_norm\": \"symmetric\",\n",
    "            \"project\": False,\n",
    "            \"initial_loops\": True,\n",
    "            \"with_nodes_own\": True,\n",
    "        },\n",
    "        \"node_params\": {\n",
    "            \"edge_to_node_aggr\": \"sum\",\n",
    "            \"project\": True,\n",
    "            \"activation\": \"relu\",\n",
    "        },\n",
    "        \"selection_params\": {\n",
    "        }\n",
    "    },\n",
    "    \"Graph_Attention\": {\n",
    "        \"edge_params\": {\n",
    "            \"edge_att_norm\": \"attention\",\n",
    "            \"project\": True,\n",
    "            \"bias\": False,\n",
    "            \"activation\": None,\n",
    "            \"initial_loops\": True,\n",
    "            \"with_nodes_own\": True\n",
    "        },\n",
    "        \"node_params\": {\n",
    "            \"edge_to_node_aggr\": \"sum\",\n",
    "            \"project\": False,\n",
    "            \"activation\": \"relu\",\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "pooling_dict = {\n",
    "    \"edge_params\": {\n",
    "        \"broadcast_method\": \"reverse_cluster\",\n",
    "        \"with_edge_weights\": True\n",
    "    },\n",
    "    \"node_params\": {\n",
    "        \"broadcast_method\": \"reverse_cluster\",\n",
    "        \"normalize\": True,\n",
    "        \"dropout_prob\" : 0.00\n",
    "    },\n",
    "    \"selection_params\": {\n",
    "        \"selection_meth\": \"mlp\",\n",
    "        \"edge_to_edge_aggr\": \"sum\",\n",
    "        \"node_to_node_aggr\": \"sum\",\n",
    "        \"project\": True,\n",
    "        \"softmax_direction\": -1,\n",
    "        \"normalize_adj\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "layer_dict = {\n",
    "    \"emb_params\": {\n",
    "        \"with_nodes_below\": True,\n",
    "        \"with_nodes_above\": True,\n",
    "        \"with_globals\": True,\n",
    "        \"with_nodes_depth\": True\n",
    "    },\n",
    "    \"pro_params\": {\n",
    "        \"with_nodes_below\": True,\n",
    "        \"with_nodes_above\": True,\n",
    "    },\n",
    "    \"dec_params\": {\n",
    "        \"with_nodes_below\": True,\n",
    "        \"with_nodes_above\": False,\n",
    "        \"with_globals\": False,\n",
    "        \"with_nodes_depth\": True,\n",
    "        \"with_selection_previous\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "setup_dict = {\"HMGN_emb\": True, \"HMGN_dec\": False, \"pos_encoding\": False, \"pos_enc_dim\": 10,\n",
    "              \"n_hid_layer\": 4, \"emb_bias\": emb_bias, \"return_type\": return_level, \n",
    "              \"patience\": 10, \"reduce_factor\": 0.5, \"initial_lr\": 5e-3, \"stop_learning_rate\": 1e-5, \n",
    "              \"seq_len\": 12, \"n_heads\": 8}\n",
    "\n",
    "if setup_dict[\"pos_encoding\"]:\n",
    "    num_features += setup_dict[\"pos_enc_dim\"]\n",
    "\n",
    "data_dict = {'n_node_feat_S': num_features, 'n_node_feat_ST': 0, 'n_feat_glob_ST': 0, \n",
    "             'n_edge_feat_S': 0, 'n_edge_feat_ST': 0, 'n_feat_glob_S': 0, \"n_out_final\" : dataset_train.num_classes}\n",
    "\n",
    "n_cluster_with_hid_list = [\n",
    "    [\"Graph_Sage_mean\", [], 100], \n",
    "    # [\"Graph_Sage_GCN\", [6], 116],\n",
    "    # [\"Graph_Sage_vanilla\", [], 146],\n",
    "    # [\"Graph_Sage_mean\", [6], 49],\n",
    "    # [\"Graph_Attention\", [], 41],\n",
    "    # [\"Graph_Sage_mean\", [64, 32, 6], 60],\n",
    "    # [\"Graph_Sage_mean\", [32, 6], 131],\n",
    "    # [\"Graph_Sage_pool\", [10], 59], \n",
    "    # [\"Graph_Sage_GCN\", [10], 100],\n",
    "    # [\"Graph_Sage_vanilla\", [10], 100],\n",
    "    # [\"Graph_Attention\", [8], 20],\n",
    "    ]\n",
    "\n",
    "for n_cluster_with_hid in n_cluster_with_hid_list:\n",
    "    model_name = n_cluster_with_hid[0]\n",
    "    n_cluster_nodes = n_cluster_with_hid[1]\n",
    "    setup_dict[\"HMGN_emb\"] = len(n_cluster_nodes) > 0\n",
    "    setup_dict[\"model_name\"] = model_name\n",
    "    setup_dict[\"n_hid\"] = n_cluster_with_hid[2]\n",
    "    hierarchical_network_params = build_network_params(model_dict[model_name], pooling_dict, data_dict,\n",
    "                                                    layer_dict, setup_dict, n_cluster_nodes)\n",
    "    model = RMGN(model_name, setup_dict, data_dict, n_cluster_nodes, hierarchical_network_params)\n",
    "    count_parameters(model, model_name, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ebaa81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27ed29a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training on:  cpu\n",
      "\n",
      " Graph_Sage_mean\n",
      "\n",
      " pro_params\n",
      "edge_params\n",
      "{'bias': True, 'globals': False, 'nodes_below': False, 'nodes_above': False, 'nodes_depth': False, 'nodes_own': True, 'edge_weights': True, 'project': False, 'initial_loops': False, 'n_feat_node': 100, 'n_out': 100}\n",
      "node_params\n",
      "{'bias': True, 'receivers': True, 'nodes_below': False, 'nodes_own': True, 'nodes_above': False, 'nodes_depth': False, 'globals': False, 'normalize': True, 'project': True, 'activation': 'relu', 'n_feat': 200, 'n_out': 100}\n",
      "\n",
      " RMGN(\n",
      "  (S_encoder): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (S_processor): ModuleList(\n",
      "    (0-3): 4 x ModuleList(\n",
      "      (0): GraphNetwork(\n",
      "        (model): ModuleList(\n",
      "          (0): EdgeModel(\n",
      "            (norm_att_fn): Normalize()\n",
      "          )\n",
      "          (1): NodeModel(\n",
      "            (node_project_fn): Linear(in_features=200, out_features=100, bias=True)\n",
      "            (activation_fn): ReLU()\n",
      "            (dropout): Dropout(p=0.05, inplace=False)\n",
      "            (normalize_fn): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (after_model): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=25, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=25, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      " Total number of Parameters  Graph_Sage_mean :  88385\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Running training on: \", device)\n",
    "\n",
    "for n_cluster_with_hid in n_cluster_with_hid_list:\n",
    "    model_name = n_cluster_with_hid[0]\n",
    "    n_cluster_nodes = n_cluster_with_hid[1]\n",
    "    setup_dict[\"HMGN_emb\"] = len(n_cluster_nodes) > 0\n",
    "    setup_dict[\"model_name\"] = model_name\n",
    "    setup_dict[\"n_hid\"] = n_cluster_with_hid[2]\n",
    "    for node_dropout_prob in [0.05]:\n",
    "        start_time = time.time()\n",
    "        all_train_accuracy, all_val_accuracy, all_test_accuracy, all_epoch = [], [], [], []\n",
    "        for seed in [0, 1, 2, 3]:\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.manual_seed(seed)\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            \n",
    "            pooling_dict[\"node_params\"][\"dropout_prob\"] = node_dropout_prob\n",
    "            hierarchical_network_params = build_network_params(model_dict[model_name], pooling_dict, data_dict,\n",
    "                                                            layer_dict, setup_dict, n_cluster_nodes)\n",
    "            print(\"\\n\", model_name)\n",
    "            for key, val in hierarchical_network_params[\"params_S\"].items():\n",
    "                print(\"\\n\", key)\n",
    "                for val2 in val:\n",
    "                    for key2, val3 in val2.items():\n",
    "                        print(key2)\n",
    "                        my_list = [\"broadcast_method\", \"dropout_prob\", \"edge_to_node_aggr\", \"with_edges_own\", \"n_feat_edge\",\n",
    "                                \"with_edges_below\", \"with_edges_above\", \"with_edges_depth\", \"edge_att_norm\",\n",
    "                                \"softmax_direction\", \"node_to_node_aggr\", \"edge_to_edge_aggr\", \"selection_meth\"]\n",
    "                        print({k.replace(\"with_\", \"\"): v for k, v in val3.items() if k not in my_list})\n",
    "\n",
    "            model_type = \"RMGN\"\n",
    "            model = RMGN(model_name, setup_dict, data_dict, n_cluster_nodes, hierarchical_network_params).to(device)\n",
    "            position_endoder = AddLaplacianEigenvectorPE(setup_dict[\"pos_enc_dim\"], attr_name=None)\n",
    "\n",
    "            if seed == 0:\n",
    "                print(\"\\n\", model)\n",
    "                count_parameters(model, model_name, False, False)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), setup_dict[\"initial_lr\"])\n",
    "\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=setup_dict[\"reduce_factor\"],\n",
    "                                                    patience= setup_dict[\"patience\"], \n",
    "                                                    verbose=True, min_lr=setup_dict[\"stop_learning_rate\"])\n",
    "\n",
    "            current_best = 0\n",
    "            best_training = 0\n",
    "            best_epoch = 0\n",
    "            for epoch in range(1000):\n",
    "                # Training loop\n",
    "                model.train()\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for snapshot in train_loader:\n",
    "                    if \"pos\" in snapshot: snapshot.x = torch.cat((snapshot.x, snapshot.pos), dim=-1)\n",
    "                    snapshot = position_endoder(snapshot)\n",
    "                    snapshot = snapshot.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    if model_type == \"RMGN\":\n",
    "                        snapshot.node_attr = snapshot.x\n",
    "                        del snapshot.x\n",
    "                        S_graphs, ST_graphs = hierarchical_graphs(n_cluster_nodes, snapshot, \n",
    "                                                    model_dict[model_name][\"edge_params\"][\"initial_loops\"])\n",
    "                        S_graphs = [graph.clone().to(device) for graph in S_graphs]\n",
    "                        ST_graphs = [graph.clone().to(device) for graph in ST_graphs]\n",
    "                        y_hat, mincut_loss, ortho_loss = model(S_graphs, ST_graphs)\n",
    "                        \n",
    "                    loss = loss_funtion(snapshot.y, y_hat, data_dict[\"n_out_final\"], device) + mincut_loss + ortho_loss\n",
    "\n",
    "                    total += snapshot.y.size(0)\n",
    "                    correct += (accuracy(snapshot.y, y_hat) * snapshot.y.size(0))\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                train_accuracy = 100.0 * correct / total\n",
    "\n",
    "                # if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch: {epoch+1}, Training Accuracy: {train_accuracy:.3f}%\")\n",
    "\n",
    "                # Validation loop\n",
    "                model.eval()\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                with torch.no_grad():\n",
    "                    for snapshot in valid_loader:\n",
    "                        if \"pos\" in snapshot: snapshot.x = torch.cat((snapshot.x, snapshot.pos), dim=-1)\n",
    "                        snapshot = position_endoder(snapshot)\n",
    "                        snapshot = snapshot.to(device)\n",
    "\n",
    "                        if model_type == \"RMGN\":\n",
    "                            snapshot.node_attr = snapshot.x\n",
    "                            del snapshot.x\n",
    "                            S_graphs, ST_graphs = hierarchical_graphs(n_cluster_nodes, snapshot, \n",
    "                                                        model_dict[model_name][\"edge_params\"][\"initial_loops\"])\n",
    "                            S_graphs = [graph.clone().to(device) for graph in S_graphs]\n",
    "                            ST_graphs = [graph.clone().to(device) for graph in ST_graphs]\n",
    "                            y_hat, mincut_loss, ortho_loss = model(S_graphs, ST_graphs)\n",
    "\n",
    "                        # y_hat = global_mean_pool(y_hat, snapshot.batch)\n",
    "                        # y_hat = after_model(y_hat)\n",
    "\n",
    "                        val_loss = loss_funtion(snapshot.y, y_hat, data_dict[\"n_out_final\"], device) + mincut_loss + ortho_loss\n",
    "\n",
    "                        total += snapshot.y.size(0)\n",
    "                        correct += (accuracy(snapshot.y, y_hat) * snapshot.y.size(0))\n",
    "\n",
    "                val_accuracy = 100.0 * correct / total\n",
    "                \n",
    "                scheduler.step(val_accuracy)\n",
    "\n",
    "                # Check if learning rate is 1e-5 or lower\n",
    "                if scheduler._last_lr[0] <= setup_dict[\"stop_learning_rate\"]:\n",
    "                    break\n",
    "\n",
    "                # if epoch == 0 or (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch: {epoch+1}, Validation Accuracy: {val_accuracy:.3f}%\")\n",
    "\n",
    "                if val_accuracy > current_best:\n",
    "                    current_best = val_accuracy\n",
    "                    best_training = train_accuracy\n",
    "                    best_epoch = epoch\n",
    "                    model_dir = \"\".join([model_root, data_name])\n",
    "                    f_name = \"_\".join([model_type, model_name, str(n_cluster_nodes), \n",
    "                                        str(setup_dict[\"n_hid_layer\"]), str(setup_dict[\"initial_lr\"]), str(node_dropout_prob), \n",
    "                                        str(setup_dict[\"n_hid\"])])\n",
    "                    # print(\"saving model!\")\n",
    "                    torch.save(model.state_dict(), model_dir + \"/\" + f_name)\n",
    "\n",
    "            model = RMGN(model_name, setup_dict, data_dict, n_cluster_nodes, hierarchical_network_params).to(device)\n",
    "\n",
    "            saved_state_dict_path = model_dir + \"/\" + f_name\n",
    "            with open(saved_state_dict_path, 'rb') as f:\n",
    "                buffer = io.BytesIO(f.read())\n",
    "\n",
    "            model.load_state_dict(torch.load(buffer))\n",
    "\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for snapshot in test_loader:\n",
    "                    if \"pos\" in snapshot: snapshot.x = torch.cat((snapshot.x, snapshot.pos), dim=-1)\n",
    "                    snapshot = position_endoder(snapshot)\n",
    "                    snapshot = snapshot.to(device)\n",
    "\n",
    "                    if model_type == \"RMGN\":\n",
    "                        snapshot.node_attr = snapshot.x\n",
    "                        del snapshot.x\n",
    "                        S_graphs, ST_graphs = hierarchical_graphs(n_cluster_nodes, snapshot, \n",
    "                                                    model_dict[model_name][\"edge_params\"][\"initial_loops\"])\n",
    "                        S_graphs = [graph.clone().to(device) for graph in S_graphs]\n",
    "                        ST_graphs = [graph.clone().to(device) for graph in ST_graphs]\n",
    "                        y_hat, mincut_loss, ortho_loss = model(S_graphs, ST_graphs)\n",
    "\n",
    "                    # y_hat = global_mean_pool(y_hat, snapshot.batch)\n",
    "                    # y_hat = after_model(y_hat)\n",
    "\n",
    "                    loss = loss_funtion(snapshot.y, y_hat, data_dict[\"n_out_final\"], device) + mincut_loss + ortho_loss\n",
    "\n",
    "                    total += snapshot.y.size(0)\n",
    "                    correct += (accuracy(snapshot.y, y_hat) * snapshot.y.size(0))\n",
    "\n",
    "            test_accuracy = 100.0 * correct / total\n",
    "            print(\"------------------------------------------------------\")\n",
    "            print(f\"Epoch: {epoch+1}, Test Accuracy: {test_accuracy:.3f}%\") \n",
    "            print(\"------------------------------------------------------\")\n",
    "            print(\"saving final model!\")\n",
    "            torch.save(model.state_dict(), model_dir + \"/\" + f_name + \"_\" + str(best_epoch) + \"_\" + str(best_training)[:4]\n",
    "                       + \"_\" + str(current_best) + \"_\" + str(test_accuracy))\n",
    "            print(\"------------------------------------------------------\")\n",
    "            \n",
    "            all_train_accuracy.append(best_training)\n",
    "            all_val_accuracy.append(current_best)\n",
    "            all_test_accuracy.append(test_accuracy)\n",
    "            all_epoch.append(best_epoch)\n",
    "        \n",
    "        print(\"Results for Model: \", model_name)\n",
    "\n",
    "        print(\"Dropout Probability: \", node_dropout_prob)\n",
    "        print(\"Number of Cluster Nodes: \", n_cluster_nodes)\n",
    "\n",
    "        print(\"Training Accuracy Mean: {:.3f}\".format(np.mean(all_train_accuracy)))\n",
    "        print(\"Training Accuracy Std Deviation: {:.3f}\".format(np.std(all_train_accuracy)))\n",
    "\n",
    "        print(\"Validation Accuracy Mean: {:.3f}\".format(np.mean(all_val_accuracy)))\n",
    "        print(\"Validation Accuracy Std Deviation: {:.3f}\".format(np.std(all_val_accuracy)))\n",
    "\n",
    "        print(\"Test Accuracy Mean: {:.3f}\".format(np.mean(all_test_accuracy)))\n",
    "        print(\"Test Accuracy Std Deviation: {:.3f}\".format(np.std(all_test_accuracy)))\n",
    "\n",
    "        print(\"Best Average Epoch: {:.3f}\".format(np.mean(all_epoch)))\n",
    "\n",
    "        print(f\"Average Runtime per Epoch: {(time.time() - start_time)/sum(all_epoch):.3f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e54b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"\".join([model_root, data_name])\n",
    "saved_state_dict_path = model_dir + \"/\" + \"RMGN_[6]_tensor(70.3675)\"\n",
    "model = torch.load(saved_state_dict_path)\n",
    "counter = 0\n",
    "for i in model:\n",
    "    if \"running_mean\" not in i and \"running_var\" not in i and \"num_batches_tracked\" not in i:\n",
    "        print(i, model[i].shape)\n",
    "    # counter += np.prod(model[i].shape)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe383ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RMGN(model_name, setup_dict, data_dict, n_cluster_nodes, hierarchical_network_params).to(device)\n",
    "model_dir = \"\".join([model_root, data_name])\n",
    "saved_state_dict_path = model_dir + \"/\" + \"RMGN_[6]_tensor(70.3675)\"\n",
    "with open(saved_state_dict_path, 'rb') as f:\n",
    "    buffer = io.BytesIO(f.read())\n",
    "\n",
    "model.load_state_dict(torch.load(buffer))\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for snapshot in train_loader:\n",
    "        if \"pos\" in snapshot: snapshot.x = torch.cat((snapshot.x, snapshot.pos), dim=-1)\n",
    "        snapshot = snapshot.to(device)\n",
    "\n",
    "        if model_type == \"RMGN\":\n",
    "            snapshot.node_attr = snapshot.x\n",
    "            del snapshot.x\n",
    "            S_graphs, ST_graphs = hierarchical_graphs(n_cluster_nodes, snapshot, \n",
    "                                        model_dict[model_name][\"edge_params\"][\"initial_loops\"])\n",
    "            S_graphs = [graph.to(device) for graph in S_graphs]\n",
    "            ST_graphs = [graph.to(device) for graph in ST_graphs]\n",
    "            y_hat, mincut_loss, ortho_loss = model(S_graphs, ST_graphs)\n",
    "\n",
    "        # y_hat = global_mean_pool(y_hat, snapshot.batch)\n",
    "        # y_hat = after_model(y_hat)\n",
    "\n",
    "        loss = loss_funtion(snapshot.y, y_hat, data_dict[\"n_out_final\"], device) + mincut_loss + ortho_loss\n",
    "\n",
    "        total += snapshot.y.size(0)\n",
    "        correct += (accuracy(snapshot.y, y_hat) * snapshot.y.size(0))\n",
    "\n",
    "    test_accuracy = 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215530e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms.add_positional_encoding import AddLaplacianEigenvectorPE\n",
    "for snapshot in train_loader:\n",
    "    break\n",
    "# test = AddLaplacianEigenvectorPE(10, attr_name=None)\n",
    "# test(snapshot)\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29056434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GAT_imlementation import GATConv\n",
    "gat_model = GATConv(5, 19, 8).cuda()\n",
    "for snapshot in test_loader:\n",
    "    if \"pos\" in snapshot: snapshot.x = torch.cat((snapshot.x, snapshot.pos), dim=-1)\n",
    "    snapshot = snapshot.to(device)\n",
    "\n",
    "    snapshot.node_attr = snapshot.x\n",
    "    del snapshot.x\n",
    "    S_graphs, ST_graphs = hierarchical_graphs(n_cluster_nodes, snapshot, \n",
    "                                model_dict[model_name][\"edge_params\"][\"initial_loops\"])\n",
    "    S_graphs = [graph.to(device) for graph in S_graphs]\n",
    "\n",
    "gat_model(S_graphs[0].node_attr, S_graphs[0].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9371112",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"The code executed in {elapsed_time / 1000} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "adj_mat = to_dense_adj(snapshot.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7cf54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming adj_mat is adjacency matrix of graph\n",
    "print((adj_mat.sum(axis=0) > 0).all() and (adj_mat.sum(axis=1) > 0).all())  # This will print True if graph is fully connected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5876e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import degree\n",
    "row = torch.tensor([0, 1, 0, 2, 0])\n",
    "degree(row, 180)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "# add edges to the graph - example ((1, 2), (1, 3), (2, 3))\n",
    "G.add_edges_from([(1, 2)])\n",
    "\n",
    "print(nx.is_connected(G))  # This will print True if graph is fully connected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a56a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.rand(100, 4)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f60e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test / test[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df12ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_accuracies = [50.489, 50.496, 50.490]\n",
    "test_accuracies = [50.37, 50.14, 50.21]\n",
    "\n",
    "print(\"Training Accuracy Mean: {:.3f}\".format(np.mean(training_accuracies)))\n",
    "print(\"Training Accuracy Std Deviation: {:.3f}\".format(np.std(training_accuracies)))\n",
    "\n",
    "print(\"Test Accuracy Mean: {:.3f}\".format(np.mean(test_accuracies)))\n",
    "print(\"Test Accuracy Std Deviation: {:.3f}\".format(np.std(test_accuracies)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfefb202",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(profile=\"full\")\n",
    "for snapshot in test_loader:\n",
    "    snapshot.node_attr = snapshot.x\n",
    "    del snapshot.x\n",
    "    S_graphs, ST_graphs = hierarchical_graphs(model_config[\"n_cluster_nodes\"], snapshot, \n",
    "                                    merged_dict[\"edge_params\"][\"with_initial_loops\"])\n",
    "    S_graphs = [graph.to(device) for graph in S_graphs]\n",
    "    ST_graphs = [graph.to(device) for graph in ST_graphs]\n",
    "    model_dir = \"\".join([model_root, dataset_train.name])\n",
    "    f_name = \"_\".join([model_type, str(n_cluster_nodes)])\n",
    "    model = RMGN(data_config, model_config, after_config).to(device)\n",
    "    saved_state_dict_path = model_dir + \"/\" + f_name\n",
    "    with open(saved_state_dict_path, 'rb') as f:\n",
    "        buffer = io.BytesIO(f.read())\n",
    "\n",
    "    model.load_state_dict(torch.load(buffer))\n",
    "    model.eval()\n",
    "    model(S_graphs, ST_graphs)\n",
    "    print(model)\n",
    "    break\n",
    "    print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e28b37b",
   "metadata": {},
   "source": [
    "\"\".join([model_root, dataset_train.name, \"/\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd35ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.S_processor[0][0].model[0].norm_att_fn.att_dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb2800",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3680a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming y_true and y_pred are 1D tensors or numpy arrays containing \n",
    "# the true and predicted class labels, respectively\n",
    "\n",
    "def calculate_weighted_accuracy(y_true, y_pred):\n",
    "    unique_classes = torch.unique(y_true)\n",
    "    class_weights = []\n",
    "    class_accuracies = []\n",
    "\n",
    "    for class_label in unique_classes:\n",
    "        class_indices = (y_true == class_label)\n",
    "        # class_accuracy = accuracy_score(y_true[class_indices], y_pred[class_indices])\n",
    "        class_accuracy += y_true[class_indices].eq(y_pred[class_indices]).sum().item() / class_indices.sum()\n",
    "        class_accuracies.append(class_accuracy)\n",
    "        class_weights.append(class_indices.sum())\n",
    "\n",
    "    # Normalize weights so they sum up to 1\n",
    "    class_weights = class_weights / class_weights.sum()\n",
    "\n",
    "    # Compute the weighted average accuracy\n",
    "    weighted_accuracy = torch.Tensor(class_accuracies) * torch.Tensor(class_weights)\n",
    "\n",
    "    return weighted_accuracy\n",
    "\n",
    "# Let's say y_true and y_pred are your ground truth and predicted labels\n",
    "y_true = torch.Tensor([0, 0, 0, 1])\n",
    "y_pred = torch.Tensor([0, 0, 0, 0])  # just for example\n",
    "\n",
    "weighted_accuracy = calculate_weighted_accuracy(y_true, y_pred)\n",
    "print(f'Weighted Accuracy: {weighted_accuracy:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d941dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y_true = torch.Tensor([0, 0, 0, 1])\n",
    "y_pred = torch.Tensor([0, 0, 0, 0])  # just for example\n",
    "\n",
    "unique_classes = torch.unique(y_true)\n",
    "class_accuracies = []\n",
    "\n",
    "for class_label in unique_classes:\n",
    "    class_indices = (y_true == class_label)\n",
    "    # class_accuracy = accuracy_score(y_true[class_indices], y_pred[class_indices])\n",
    "    class_accuracy = y_true[class_indices].eq(y_pred[class_indices]).sum().item() / class_indices.sum()\n",
    "    class_accuracies.append(class_accuracy)\n",
    "\n",
    "weighted_accuracy = torch.Tensor(class_accuracies).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a514b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb0a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "test = torch.nn.Embedding(7, 108).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb3a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(snapshot.node_attr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb7980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.S_processor[0][0].model[0].norm_att_fn.att_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5699e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def node_to_node_broadcast(broadcast_method, graphs, idx):\n",
    "#     batch_size = len(graphs[idx][\"ptr\"]) -1\n",
    "#     s_dim = graphs[idx].selection.shape\n",
    "#     v_dim = graphs[idx+1].node_attr.shape\n",
    "#     s_dim = [batch_size] + [int(s_dim[0] / batch_size)] + list(s_dim[1:])\n",
    "#     v_dim = [batch_size] + [int(v_dim[0] / batch_size)] + list(v_dim[1:])\n",
    "#     if len(v_dim) == 3:\n",
    "#         return torch.einsum(\"abc, acd -> abd\", graphs[idx].selection.reshape(s_dim), graphs[idx+1].node_attr.reshape(v_dim)).flatten(end_dim=1)\n",
    "#     else:\n",
    "#         return torch.einsum(\"abc, acde -> abde\", graphs[idx].selection.reshape(s_dim), graphs[idx+1].node_attr.reshape(v_dim)).flatten(end_dim=1)\n",
    "        \n",
    "def node_to_node_broadcast(broadcast_method, graphs, idx):\n",
    "    nodes_per_graph = graphs[idx].ptr[1:] - graphs[idx].ptr[:-1]\n",
    "    broadcasted_attrs = torch.repeat_interleave(graphs[idx+1].node_attr, nodes_per_graph, dim=0)\n",
    "    weighted_broadcasted_attr = broadcasted_attrs * graphs[idx].selection\n",
    "    return weighted_broadcasted_attr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter\n",
    "scatter(snapshot.edge_attr, snapshot.edge_index[1], dim=0, reduce=\"sum\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "segment_ids = torch.tensor([0, 0, 2])\n",
    "scatter(data, segment_ids, dim=0, dim_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841e0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot.batch[snapshot.edge_index[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a54e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot.edge_index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6a460c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
